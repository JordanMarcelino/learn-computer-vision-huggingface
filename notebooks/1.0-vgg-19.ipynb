{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Network Architechture\n",
    "\n",
    "-   Inputs are 224x224 images.\n",
    "-   Convolution kernel shape is (3,3) and max pooling window shape is (2,2).\n",
    "-   Number of channels for each convolutional layer 64 -> 128 -> 256 -> 512 -> 512.\n",
    "-   VGG16 has 16 hidden layers (13 convolutional layers and 3 fully connected layers).\n",
    "-   VGG19 has 19 hidden layers (16 convolutional layers and 3 fully connected layers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Comparisons\n",
    "\n",
    "-   VGG (16 or 19 layers) was relatively deeper than other SOTA networks at the time. AlexNet, the winning model for ILSVRC 2012 only has 8 layers.\n",
    "-   Multiple small (3X3) receptive field filters with ReLU activation instead of one large (7X7 or 11X11) filter lead to better learning of complex features. Smaller filters also mean fewer parameters per layer, with additional nonlinearity introduced in between.\n",
    "-   Multiscale training and inference. Each image was trained in multiple rounds with varying scales to ensure similar characteristics were captured at different sizes.\n",
    "-   Consistency and simplicity of the VGG network make it easier to scale or modify for future improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG19, self).__init__()\n",
    "\n",
    "        # Feature extraction layers: Convolutional and pooling layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                3, 64, kernel_size=3, padding=1\n",
    "            ),  # 3 input channels, 64 output channels, 3x3 kernel, 1 padding\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2, stride=2\n",
    "            ),  # Max pooling with 2x2 kernel and stride 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                512 * 7 * 7, 4096\n",
    "            ),  # 512 channels, 7x7 spatial dimensions after max pooling\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout layer with 0.5 dropout probability\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(\n",
    "                4096, num_classes\n",
    "            ),  # Output layer with 'num_classes' output units\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)  # Pass input through the feature extractor layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layers\n",
    "        x = self.classifier(x)  # Pass flattened output through the classifier layers\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "VGG19 (VGG19)                            [1, 3, 224, 224]     [1, 1000]            --                   True\n",
       "├─Sequential (feature_extractor)         [1, 3, 224, 224]     [1, 512, 7, 7]       --                   True\n",
       "│    └─Conv2d (0)                        [1, 3, 224, 224]     [1, 64, 224, 224]    1,792                True\n",
       "│    └─ReLU (1)                          [1, 64, 224, 224]    [1, 64, 224, 224]    --                   --\n",
       "│    └─Conv2d (2)                        [1, 64, 224, 224]    [1, 64, 224, 224]    36,928               True\n",
       "│    └─ReLU (3)                          [1, 64, 224, 224]    [1, 64, 224, 224]    --                   --\n",
       "│    └─MaxPool2d (4)                     [1, 64, 224, 224]    [1, 64, 112, 112]    --                   --\n",
       "│    └─Conv2d (5)                        [1, 64, 112, 112]    [1, 128, 112, 112]   73,856               True\n",
       "│    └─ReLU (6)                          [1, 128, 112, 112]   [1, 128, 112, 112]   --                   --\n",
       "│    └─Conv2d (7)                        [1, 128, 112, 112]   [1, 128, 112, 112]   147,584              True\n",
       "│    └─ReLU (8)                          [1, 128, 112, 112]   [1, 128, 112, 112]   --                   --\n",
       "│    └─MaxPool2d (9)                     [1, 128, 112, 112]   [1, 128, 56, 56]     --                   --\n",
       "│    └─Conv2d (10)                       [1, 128, 56, 56]     [1, 256, 56, 56]     295,168              True\n",
       "│    └─ReLU (11)                         [1, 256, 56, 56]     [1, 256, 56, 56]     --                   --\n",
       "│    └─MaxPool2d (12)                    [1, 256, 56, 56]     [1, 256, 28, 28]     --                   --\n",
       "│    └─Conv2d (13)                       [1, 256, 28, 28]     [1, 256, 28, 28]     590,080              True\n",
       "│    └─ReLU (14)                         [1, 256, 28, 28]     [1, 256, 28, 28]     --                   --\n",
       "│    └─Conv2d (15)                       [1, 256, 28, 28]     [1, 256, 28, 28]     590,080              True\n",
       "│    └─ReLU (16)                         [1, 256, 28, 28]     [1, 256, 28, 28]     --                   --\n",
       "│    └─Conv2d (17)                       [1, 256, 28, 28]     [1, 256, 28, 28]     590,080              True\n",
       "│    └─ReLU (18)                         [1, 256, 28, 28]     [1, 256, 28, 28]     --                   --\n",
       "│    └─MaxPool2d (19)                    [1, 256, 28, 28]     [1, 256, 14, 14]     --                   --\n",
       "│    └─Conv2d (20)                       [1, 256, 14, 14]     [1, 512, 14, 14]     1,180,160            True\n",
       "│    └─ReLU (21)                         [1, 512, 14, 14]     [1, 512, 14, 14]     --                   --\n",
       "│    └─Conv2d (22)                       [1, 512, 14, 14]     [1, 512, 14, 14]     2,359,808            True\n",
       "│    └─ReLU (23)                         [1, 512, 14, 14]     [1, 512, 14, 14]     --                   --\n",
       "│    └─Conv2d (24)                       [1, 512, 14, 14]     [1, 512, 14, 14]     2,359,808            True\n",
       "│    └─ReLU (25)                         [1, 512, 14, 14]     [1, 512, 14, 14]     --                   --\n",
       "│    └─Conv2d (26)                       [1, 512, 14, 14]     [1, 512, 14, 14]     2,359,808            True\n",
       "│    └─ReLU (27)                         [1, 512, 14, 14]     [1, 512, 14, 14]     --                   --\n",
       "│    └─MaxPool2d (28)                    [1, 512, 14, 14]     [1, 512, 7, 7]       --                   --\n",
       "├─Sequential (classifier)                [1, 25088]           [1, 1000]            --                   True\n",
       "│    └─Linear (0)                        [1, 25088]           [1, 4096]            102,764,544          True\n",
       "│    └─ReLU (1)                          [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Dropout (2)                       [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Linear (3)                        [1, 4096]            [1, 4096]            16,781,312           True\n",
       "│    └─ReLU (4)                          [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Dropout (5)                       [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Linear (6)                        [1, 4096]            [1, 1000]            4,097,000            True\n",
       "========================================================================================================================\n",
       "Total params: 134,228,008\n",
       "Trainable params: 134,228,008\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.78\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 91.59\n",
       "Params size (MB): 536.91\n",
       "Estimated Total Size (MB): 629.11\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model=model,\n",
    "    input_size=(1, 3, 224, 224),  # (batch_size, color_channels, height, width)\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn((1, 3, 224, 224))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
